{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49043d2e",
   "metadata": {},
   "source": [
    "## Steps\n",
    "\n",
    "1. Let VADER program identify the sentiment of all the tweets in SentEval dev dataset.\n",
    "2. Check VADER's accuracy against SentEval's\n",
    "3. ~~Assuming accuracy is sufficient, figure out if/how to use TwitterScraper for getting topics.~~\n",
    "4. Do some text cleaning on the tweets.\n",
    "5. Check VADER's accuracy against SentEval's, once again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cc32ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install stuff\n",
    "pip install twitterscraper vaderSentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92f346d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f489d76",
   "metadata": {},
   "source": [
    "## #0 - Constructing DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f312f0d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41700</th>\n",
       "      <td>681877834982232064</td>\n",
       "      <td>neutral</td>\n",
       "      <td>@ShaquilleHoNeal from what I think you're aski...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41701</th>\n",
       "      <td>681879579129200640</td>\n",
       "      <td>positive</td>\n",
       "      <td>Iran ranks 1st in liver surgeries, Allah bless...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41702</th>\n",
       "      <td>681883903259357184</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Hours before he arrived in Saudi Arabia on Tue...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41703</th>\n",
       "      <td>681904976860327936</td>\n",
       "      <td>negative</td>\n",
       "      <td>@VanityFair  Alex Kim Kardashian worth how to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41704</th>\n",
       "      <td>681910549211287552</td>\n",
       "      <td>neutral</td>\n",
       "      <td>I guess even Pandora knows Justin Bieber is a ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id sentiment  \\\n",
       "41700  681877834982232064   neutral   \n",
       "41701  681879579129200640  positive   \n",
       "41702  681883903259357184   neutral   \n",
       "41703  681904976860327936  negative   \n",
       "41704  681910549211287552   neutral   \n",
       "\n",
       "                                                    text  \n",
       "41700  @ShaquilleHoNeal from what I think you're aski...  \n",
       "41701  Iran ranks 1st in liver surgeries, Allah bless...  \n",
       "41702  Hours before he arrived in Saudi Arabia on Tue...  \n",
       "41703  @VanityFair  Alex Kim Kardashian worth how to ...  \n",
       "41704  I guess even Pandora knows Justin Bieber is a ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The two files moved to the GOLD/SHIT folder could not be used.\n",
    "# Some entries are not properly tab separated and the tweets are merged together.\n",
    "\n",
    "path = os.path.join('Datasets/semeval-datasets/2017_English_final/GOLD/Subtask_A')\n",
    "txt_files = glob.glob(os.path.join(path, 'twitter*.txt'))\n",
    "list_ = []\n",
    "\n",
    "for file in txt_files:\n",
    "    df = pd.read_csv(file, index_col=None, sep='\\t', header=None,\n",
    "                        names=['id', 'sentiment', 'text', 'to_delete'])\n",
    "    \n",
    "    list_.append(df.iloc[:, :-1])\n",
    "    \n",
    "df = pd.concat(list_)\n",
    "df = df.drop_duplicates()\n",
    "df = df.reset_index(drop=True)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3df18db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 41705 entries, 0 to 41704\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   id         41705 non-null  int64 \n",
      " 1   sentiment  41705 non-null  object\n",
      " 2   text       41705 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 977.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfc22610",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['token_length'] = [ len(x.split(\" \")) for x in df.text ]\n",
    "max(df.token_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "389500c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_columns_index(df, column_types='all'):\n",
    "    if column_types == 'all':\n",
    "        return df.columns\n",
    "    else:\n",
    "        numeric_cols = df.select_dtypes(include=np.number).columns\n",
    "        if column_types == 'numeric':\n",
    "            return numeric_cols\n",
    "        elif column_types == 'non-numeric':\n",
    "            return pd.Index(set(df.columns).difference(set(numeric_cols)))\n",
    "        else:\n",
    "            return df.select_dtypes(include=column_types).columns\n",
    "\n",
    "def print_missing_per_col(df, column_types='all'):\n",
    "    def _print_missing_col(df, cols):\n",
    "        print(f\"Percent missing by column ({column_types})\".center(32))\n",
    "        for col in cols:\n",
    "            p_missing = round(np.mean(df[col].isnull()), 5)\n",
    "            print(f'{col} '.ljust(34, '.'), f'{p_missing*100}%')\n",
    "\n",
    "    _print_missing_col(df, get_columns_index(df, column_types))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98dda430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent missing by column (all) \n",
      "id ............................... 0.0%\n",
      "sentiment ........................ 0.0%\n",
      "text ............................. 0.0%\n",
      "token_length ..................... 0.0%\n"
     ]
    }
   ],
   "source": [
    "print_missing_per_col(df) # Verifying no missing data first"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7c1d49",
   "metadata": {},
   "source": [
    "##  #1/2 - vaderSentiment time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73c8c997",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()\n",
    "vader_sentiments = []\n",
    "\n",
    "for tweet in df['text']:\n",
    "    sent = 'neutral'\n",
    "    compound_score = analyzer.polarity_scores(tweet)['compound']\n",
    "    if compound_score >= 0.05:\n",
    "        sent = 'positive'\n",
    "    elif compound_score <= -0.05:\n",
    "        sent = 'negative'\n",
    "    vader_sentiments.append(sent)\n",
    "    \n",
    "df['vader_sentiment'] = vader_sentiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b3b88d",
   "metadata": {},
   "source": [
    "### Checking VaderSentiment's sentiment classification vs SemEval's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a79a20dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "vader_sentiment_matches = []\n",
    "for index, row in df.iterrows():\n",
    "    match = 1 if row['sentiment'] == row['vader_sentiment'] else 0\n",
    "    vader_sentiment_matches.append(match)\n",
    "df['vader_sentiment_match'] = vader_sentiment_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6fc0d98b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched rows:     23332\n",
      "Percentage match: 55.94533029612756%\n"
     ]
    }
   ],
   "source": [
    "n_matched_rows = df[df['vader_sentiment_match'] == 1].count()['vader_sentiment_match']\n",
    "print(f\"Matched rows:     {n_matched_rows}\")\n",
    "print(f\"Percentage match: {(n_matched_rows/df.shape[0])*100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc102a52",
   "metadata": {},
   "source": [
    "#### Without any cleaning of the SemEval tweets fed to VADER, only 56% of VaderSentiment's labels match SemEval's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9468889",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41705, 6)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8984948a",
   "metadata": {},
   "source": [
    "## #4 - Text Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8297c4",
   "metadata": {},
   "source": [
    "1. Replace ’(apostrophes) with ' (single quotes)\n",
    "2. Remove square brackets, links, punctuation\n",
    "3. Remove @mentions\n",
    "4. Remove the unicode bullshit\n",
    "5. Tokenize\n",
    "6. Replace contractions with uncontracted forms\n",
    "7. Lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab658696",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_title(title):\n",
    "    print(f\"{title}\", end=\"\\n\"+\"-\"*44+\"\\n\")\n",
    "\n",
    "def regex_sub(df, text_col, regex, substitute=''):\n",
    "    r = re.compile(regex)\n",
    "    for i, text in enumerate(df[text_col]):\n",
    "        df[text_col].iloc[i] = re.sub(r, substitute, text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cafc444f",
   "metadata": {},
   "source": [
    "### #1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6e5488c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Austin Kincer\\AppData\\Local\\Temp\\ipykernel_6640\\1137679944.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[text_col].iloc[i] = re.sub(r, substitute, text)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mA:\\ProgramData\\Anaconda3\\lib\\genericpath.py:19\u001b[0m, in \u001b[0;36mexists\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 19\u001b[0m     \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mOSError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'C:\\\\Users\\\\Austin Kincer\\\\AppData\\\\Local\\\\Temp\\\\ipykernel_6640\\\\1137679944.py'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#1. Replace ’(apostrophes) with ' (single quotes)\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mregex_sub\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m’\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [11]\u001b[0m, in \u001b[0;36mregex_sub\u001b[1;34m(df, text_col, regex, substitute)\u001b[0m\n\u001b[0;32m      5\u001b[0m r \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39mcompile(regex)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, text \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(df[text_col]):\n\u001b[1;32m----> 7\u001b[0m     df[text_col]\u001b[38;5;241m.\u001b[39miloc[i] \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(r, substitute, text)\n",
      "File \u001b[1;32mA:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:716\u001b[0m, in \u001b[0;36m_LocationIndexer.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m    713\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_valid_setitem_indexer(key)\n\u001b[0;32m    715\u001b[0m iloc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miloc\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39miloc\n\u001b[1;32m--> 716\u001b[0m \u001b[43miloc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setitem_with_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mA:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1690\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer\u001b[1;34m(self, indexer, value, name)\u001b[0m\n\u001b[0;32m   1688\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_with_indexer_split_path(indexer, value, name)\n\u001b[0;32m   1689\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1690\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setitem_single_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mA:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1935\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_single_block\u001b[1;34m(self, indexer, value, name)\u001b[0m\n\u001b[0;32m   1932\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_align_frame(indexer, value)\n\u001b[0;32m   1934\u001b[0m \u001b[38;5;66;03m# check for chained assignment\u001b[39;00m\n\u001b[1;32m-> 1935\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_is_chained_assignment_possible\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1937\u001b[0m \u001b[38;5;66;03m# actually do the set\u001b[39;00m\n\u001b[0;32m   1938\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39msetitem(indexer\u001b[38;5;241m=\u001b[39mindexer, value\u001b[38;5;241m=\u001b[39mvalue)\n",
      "File \u001b[1;32mA:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py:1256\u001b[0m, in \u001b[0;36mSeries._check_is_chained_assignment_possible\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1254\u001b[0m     ref \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_cacher()\n\u001b[0;32m   1255\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ref \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m ref\u001b[38;5;241m.\u001b[39m_is_mixed_type:\n\u001b[1;32m-> 1256\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_setitem_copy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreferent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   1257\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1258\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m_check_is_chained_assignment_possible()\n",
      "File \u001b[1;32mA:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:4030\u001b[0m, in \u001b[0;36mNDFrame._check_setitem_copy\u001b[1;34m(self, t, force)\u001b[0m\n\u001b[0;32m   4028\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m com\u001b[38;5;241m.\u001b[39mSettingWithCopyError(t)\n\u001b[0;32m   4029\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m value \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 4030\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(t, com\u001b[38;5;241m.\u001b[39mSettingWithCopyWarning, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[43mfind_stack_level\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mA:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\util\\_exceptions.py:32\u001b[0m, in \u001b[0;36mfind_stack_level\u001b[1;34m()\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfind_stack_level\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;124;03m    Find the first place in the stack that is not inside pandas\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;124;03m    (tests notwithstanding).\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m     stack \u001b[38;5;241m=\u001b[39m \u001b[43minspect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m     36\u001b[0m     pkg_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(pd\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__file__\u001b[39m)\n",
      "File \u001b[1;32mA:\\ProgramData\\Anaconda3\\lib\\inspect.py:1526\u001b[0m, in \u001b[0;36mstack\u001b[1;34m(context)\u001b[0m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstack\u001b[39m(context\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m   1525\u001b[0m     \u001b[38;5;124;03m\"\"\"Return a list of records for the stack above the caller's frame.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1526\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgetouterframes\u001b[49m\u001b[43m(\u001b[49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getframe\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mA:\\ProgramData\\Anaconda3\\lib\\inspect.py:1503\u001b[0m, in \u001b[0;36mgetouterframes\u001b[1;34m(frame, context)\u001b[0m\n\u001b[0;32m   1501\u001b[0m framelist \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m frame:\n\u001b[1;32m-> 1503\u001b[0m     frameinfo \u001b[38;5;241m=\u001b[39m (frame,) \u001b[38;5;241m+\u001b[39m \u001b[43mgetframeinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1504\u001b[0m     framelist\u001b[38;5;241m.\u001b[39mappend(FrameInfo(\u001b[38;5;241m*\u001b[39mframeinfo))\n\u001b[0;32m   1505\u001b[0m     frame \u001b[38;5;241m=\u001b[39m frame\u001b[38;5;241m.\u001b[39mf_back\n",
      "File \u001b[1;32mA:\\ProgramData\\Anaconda3\\lib\\inspect.py:1477\u001b[0m, in \u001b[0;36mgetframeinfo\u001b[1;34m(frame, context)\u001b[0m\n\u001b[0;32m   1475\u001b[0m start \u001b[38;5;241m=\u001b[39m lineno \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m context\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[0;32m   1476\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1477\u001b[0m     lines, lnum \u001b[38;5;241m=\u001b[39m \u001b[43mfindsource\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1478\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[0;32m   1479\u001b[0m     lines \u001b[38;5;241m=\u001b[39m index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mA:\\ProgramData\\Anaconda3\\lib\\inspect.py:780\u001b[0m, in \u001b[0;36mfindsource\u001b[1;34m(object)\u001b[0m\n\u001b[0;32m    772\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfindsource\u001b[39m(\u001b[38;5;28mobject\u001b[39m):\n\u001b[0;32m    773\u001b[0m     \u001b[38;5;124;03m\"\"\"Return the entire source file and starting line number for an object.\u001b[39;00m\n\u001b[0;32m    774\u001b[0m \n\u001b[0;32m    775\u001b[0m \u001b[38;5;124;03m    The argument may be a module, class, method, function, traceback, frame,\u001b[39;00m\n\u001b[0;32m    776\u001b[0m \u001b[38;5;124;03m    or code object.  The source code is returned as a list of all the lines\u001b[39;00m\n\u001b[0;32m    777\u001b[0m \u001b[38;5;124;03m    in the file and the line number indexes a line in that list.  An OSError\u001b[39;00m\n\u001b[0;32m    778\u001b[0m \u001b[38;5;124;03m    is raised if the source code cannot be retrieved.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 780\u001b[0m     file \u001b[38;5;241m=\u001b[39m \u001b[43mgetsourcefile\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mobject\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    781\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m file:\n\u001b[0;32m    782\u001b[0m         \u001b[38;5;66;03m# Invalidate cache if needed.\u001b[39;00m\n\u001b[0;32m    783\u001b[0m         linecache\u001b[38;5;241m.\u001b[39mcheckcache(file)\n",
      "File \u001b[1;32mA:\\ProgramData\\Anaconda3\\lib\\inspect.py:705\u001b[0m, in \u001b[0;36mgetsourcefile\u001b[1;34m(object)\u001b[0m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28many\u001b[39m(filename\u001b[38;5;241m.\u001b[39mendswith(s) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m\n\u001b[0;32m    703\u001b[0m              importlib\u001b[38;5;241m.\u001b[39mmachinery\u001b[38;5;241m.\u001b[39mEXTENSION_SUFFIXES):\n\u001b[0;32m    704\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 705\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexists\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m filename\n\u001b[0;32m    707\u001b[0m \u001b[38;5;66;03m# only return a non-existent filename if the module has a PEP 302 loader\u001b[39;00m\n",
      "File \u001b[1;32mA:\\ProgramData\\Anaconda3\\lib\\genericpath.py:19\u001b[0m, in \u001b[0;36mexists\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03m\"\"\"Test whether a path exists.  Returns False for broken symbolic links\"\"\"\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 19\u001b[0m     \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mOSError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#1. Replace ’(apostrophes) with ' (single quotes)\n",
    "regex_sub(df, 'text', \"’\", \"'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "11e95303",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>vader_sentiment</th>\n",
       "      <th>vader_sentiment_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, sentiment, text, vader_sentiment, vader_sentiment_match]\n",
       "Index: []"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify since above warning\n",
    "df[df['text'].str.contains(\"’\")][:3] # Checks out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999536f9",
   "metadata": {},
   "source": [
    "###  #2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "e57c0c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_12004\\1137679944.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[text_col].iloc[i] = re.sub(r, substitute, text)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_12004\\1678140715.py:11: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['text'] = df['text'].str.replace(r\"[^\\w\\s]\",'')\n"
     ]
    }
   ],
   "source": [
    "#2. Remove square brackets, links, punctuation -- takes a long time ;P\n",
    "\n",
    "# Remove square brackets\n",
    "regex_sub(df, 'text', r\"\\W*\\[(.*?)\\]\")\n",
    "\n",
    "# Remove links\n",
    "url_regex = r\"(https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|www\\.[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9]+\\.[^\\s]{2,}|www\\.[a-zA-Z0-9]+\\.[^\\s]{2,})\"\n",
    "regex_sub(df, 'text', url_regex)\n",
    "\n",
    "# Remove punctuation\n",
    "df['text'] = df['text'].str.replace(r\"[^\\w\\s]\",'')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28fc0177",
   "metadata": {},
   "source": [
    "###  #3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "6e44b066",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_12004\\1137679944.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[text_col].iloc[i] = re.sub(r, substitute, text)\n"
     ]
    }
   ],
   "source": [
    "#3. Remove @mentions\n",
    "regex_sub(df, 'text', r\"\\B@\\S+\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271328c3",
   "metadata": {},
   "source": [
    "### #4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "a0443442",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>vader_sentiment</th>\n",
       "      <th>vader_sentiment_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5193</th>\n",
       "      <td>264183816548130816</td>\n",
       "      <td>positive</td>\n",
       "      <td>Gas by my house hit 339 Iu2019m going to Chape...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id sentiment  \\\n",
       "5193  264183816548130816  positive   \n",
       "\n",
       "                                                   text vader_sentiment  \\\n",
       "5193  Gas by my house hit 339 Iu2019m going to Chape...        positive   \n",
       "\n",
       "      vader_sentiment_match  \n",
       "5193                      1  "
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['text'].str.contains('Gas by my house hit')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "b1ad0a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_12004\\1137679944.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[text_col].iloc[i] = re.sub(r, substitute, text)\n"
     ]
    }
   ],
   "source": [
    "regex_sub(df, 'text', r\"\\\\u\\S+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "3d18aa17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20    Gary Ablett wins the AFLPA MVP for the 4th tim...\n",
      "Name: text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Check for a specific unicode char I saw in a tweet\n",
    "t = df[df['text'].str.contains('He should have started his speech with')]['text']\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce926c37",
   "metadata": {},
   "source": [
    "### #5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "1e03dc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = nltk.tokenize.WordPunctTokenizer()\n",
    "def tokenize(text, remove_punctuation=True, preserve_case=True):\n",
    "    text = regex_sub_str(text, r\"[^\\w\\s]\", '') if remove_punctuation else text\n",
    "    if preserve_case:\n",
    "        return [ word for word in tokenizer.tokenize(text) ]\n",
    "    else:\n",
    "        return [ word.lower() for word in tokenizer.tokenize(text) ]\n",
    "    \n",
    "def tokenize_column(df, text_col, remove_punctuation=True, preserve_case=True):\n",
    "    tokens_list = []\n",
    "    for text in df[text_col]:\n",
    "        tokens = tokenize(text, remove_punctuation, preserve_case)\n",
    "        tokens_list.append(tokens)\n",
    "    return tokens_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "0d34547e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize\n",
    "df['text_tokenized'] = tokenize_column(df, 'text', remove_punctuation=False) # Already removed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d75257b",
   "metadata": {},
   "source": [
    "### #6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "c041ab39",
   "metadata": {},
   "outputs": [],
   "source": [
    "contractions_map = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \n",
    "                   \"can't've\": \"cannot have\", \"'cause\": \"because\", \"could've\": \"could have\", \n",
    "                   \"couldn't\": \"could not\", \"couldn't've\": \"could not have\",\"didn't\": \"did not\", \n",
    "                   \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \n",
    "                   \"hadn't've\": \"had not have\", \"hasn't\": \"has not\", \"haven't\": \"have not\", \n",
    "                   \"he'd\": \"he would\", \"he'd've\": \"he would have\", \"he'll\": \"he will\", \n",
    "                   \"he'll've\": \"he will have\", \"he's\": \"he is\", \"how'd\": \"how did\", \n",
    "                   \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\", \n",
    "                   \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \n",
    "                   \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \n",
    "                   \"i'd\": \"i would\", \"i'd've\": \"i would have\", \"i'll\": \"i will\", \n",
    "                   \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \n",
    "                   \"isn't\": \"is not\", \"it'd\": \"it would\", \"it'd've\": \"it would have\", \n",
    "                   \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \n",
    "                   \"let's\": \"let us\", \"ma'am\": \"madam\", \"mayn't\": \"may not\", \n",
    "                   \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \n",
    "                   \"must've\": \"must have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \n",
    "                   \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\", \n",
    "                   \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\",\n",
    "                   \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \n",
    "                   \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \n",
    "                   \"she's\": \"she is\", \"should've\": \"should have\", \"shouldn't\": \"should not\", \n",
    "                   \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\", \n",
    "                   \"this's\": \"this is\",\n",
    "                   \"that'd\": \"that would\", \"that'd've\": \"that would have\",\"that's\": \"that is\", \n",
    "                   \"there'd\": \"there would\", \"there'd've\": \"there would have\",\"there's\": \"there is\", \n",
    "                       \"here's\": \"here is\",\n",
    "                   \"they'd\": \"they would\", \"they'd've\": \"they would have\", \"they'll\": \"they will\", \n",
    "                   \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \n",
    "                   \"to've\": \"to have\", \"wasn't\": \"was not\", \"we'd\": \"we would\", \n",
    "                   \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \n",
    "                   \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\", \n",
    "                   \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\", \n",
    "                   \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \n",
    "                   \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\", \n",
    "                   \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \n",
    "                   \"who's\": \"who is\", \"who've\": \"who have\", \"why's\": \"why is\", \n",
    "                   \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \n",
    "                   \"won't've\": \"will not have\", \"would've\": \"would have\", \"wouldn't\": \"would not\", \n",
    "                   \"wouldn't've\": \"would not have\", \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\n",
    "                   \"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "                   \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \n",
    "                   \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\" } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "0ee08a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "contractions_keys = contractions_map.keys()\n",
    "\n",
    "def replace_contractions(tokens):\n",
    "    return [ contractions_map[t] if t in contractions_keys else t for t in tokens ]\n",
    "    \n",
    "def replace_contractions_column(df, tokens_col):\n",
    "    return [ replace_contractions(tokens) for tokens in df[tokens_col] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "116b9ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace contractions with uncontracted forms\n",
    "df['text_tokenized'] = replace_contractions_column(df, 'text_tokenized')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961fe431",
   "metadata": {},
   "source": [
    "###  #7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "250d2c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "def lemmatize_tokens(tokens):\n",
    "    return [ wordnet_lemmatizer.lemmatize(token) for token in tokens ]\n",
    "\n",
    "def lemmatize_tokens_column(df, tokens_col):\n",
    "    return [ lemmatize_tokens(tokens) for tokens in df[tokens_col] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "b7db7172",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. Lemmatize\n",
    "df['text_tokenized'] = lemmatize_tokens_column(df, 'text_tokenized')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626660ac",
   "metadata": {},
   "source": [
    "## # 5. - Re-checking VADER labels vs. SemEval labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "4209a8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redo vader sentiment\n",
    "vader_sentiments.clear()\n",
    "\n",
    "for tweet in df['text']:\n",
    "    sent = 'neutral'\n",
    "    compound_score = analyzer.polarity_scores(tweet)['compound']\n",
    "    if compound_score >= 0.05:\n",
    "        sent = 'positive'\n",
    "    elif compound_score <= -0.05:\n",
    "        sent = 'negative'\n",
    "    vader_sentiments.append(sent)\n",
    "    \n",
    "df['vader_sentiment'] = vader_sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "ae0e80f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vader_sentiment_matches = []\n",
    "for index, row in df.iterrows():\n",
    "    match = 1 if row['sentiment'] == row['vader_sentiment'] else 0\n",
    "    vader_sentiment_matches.append(match)\n",
    "df['vader_sentiment_match'] = vader_sentiment_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "7b1a354c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched rows:     22925\n",
      "Percentage match: 54.969428126123965%\n"
     ]
    }
   ],
   "source": [
    "n_matched_rows = df[df['vader_sentiment_match'] == 1].count()['vader_sentiment_match']\n",
    "print(f\"Matched rows:     {n_matched_rows}\")\n",
    "print(f\"Percentage match: {(n_matched_rows/df.shape[0])*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95232b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
