{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5c7d91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "\n",
    "from cleantext import clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04725e2",
   "metadata": {},
   "source": [
    "# Define Dataset Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc2001a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#'twitter', 'semeval'\n",
    "\n",
    "#dataset = 'twitter'\n",
    "dataset = 'semeval'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3ec4b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Twitter\n",
    "if dataset == 'twitter':\n",
    "    relative_import_path = 'Datasets/ScrapedTwitter/'\n",
    "    relative_export_path = 'Datasets/TwitterCleaned/'\n",
    "\n",
    "    dataset_files = ['dino_tweets_15k.csv', 'league_tweets_15k.csv', 'musk_tweets_15k.csv']\n",
    "    names=None\n",
    "    sep=','\n",
    "    header='infer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc94c938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Semeval\n",
    "if dataset == 'semeval':\n",
    "    relative_import_path = 'Datasets/semeval-datasets/2017_English_final/GOLD/Subtask_A/'\n",
    "    relative_export_path = 'Datasets/SemevalCleaned/'\n",
    "    names = ['id', 'sentiment', 'tweet', 'blah']\n",
    "    sep='\\t'\n",
    "    header=None\n",
    "\n",
    "    # Get the file names\n",
    "    import_files = glob.glob(os.path.join(relative_import_path, 'twitter*.txt'))\n",
    "\n",
    "    # Get the dataset file names\n",
    "    dataset_files = []\n",
    "    for file in import_files:\n",
    "        (head, tail) = os.path.split(file)\n",
    "        dataset_files.append(tail)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db7a90c",
   "metadata": {},
   "source": [
    "# Define text cleaning functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4256d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def removePunctTokens(tokens):\n",
    "    punctuation = set(string.punctuation) \n",
    "    newTokens = []\n",
    "    for token in tokens:\n",
    "        if token in punctuation:\n",
    "            continue\n",
    "        else:\n",
    "            newTokens.append(token)\n",
    "            \n",
    "def replaceWithSpaces(string, characters):\n",
    "    puncutation = set(characters)\n",
    "    outString = string\n",
    "    for character in characters:\n",
    "        outString = outString.replace(character, ' ')\n",
    "        \n",
    "    return outString\n",
    "\n",
    "def removeHtml(string):\n",
    "    outstring = re.sub('<a [^<]*>', '', string)\n",
    "    outstring = re.sub('<\\/a>', '', outstring)\n",
    "    outstring = outstring.replace('</a>', '')\n",
    "    outstring = outstring.replace('<br />', '')\n",
    "    \n",
    "    return outstring\n",
    "\n",
    "def removeStartingRetweet(string):\n",
    "    return re.sub('^RT @.*?: ', '', string)\n",
    "\n",
    "def removeLink(string):\n",
    "    pattern = r\"(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\\\".,<>?«»“”‘’]))\"\n",
    "    \n",
    "    return re.sub(pattern, ' ', string)\n",
    "\n",
    "def removeAts(string):\n",
    "    return re.sub('@\\w*', ' ', string)\n",
    "\n",
    "def removeHashtags(string):\n",
    "    return re.sub('#\\w*', ' ', string)\n",
    "\n",
    "def collapseWhitespace(string):\n",
    "    return re.sub('\\s+', ' ', string)\n",
    "\n",
    "def cleanDirtyWebText(string):\n",
    "    return clean(string, no_emoji=True, no_emails=True, no_phone_numbers=True, replace_with_email=' ', replace_with_phone_number=' ')\n",
    "\n",
    "def cleanTweet(string):\n",
    "    string = removeStartingRetweet(string)\n",
    "    string = cleanDirtyWebText(string)\n",
    "    string = removeAts(string)\n",
    "    string = removeLink(string)\n",
    "    string = removeHashtags(string)\n",
    "    string = collapseWhitespace(string)\n",
    "    \n",
    "    # Remove starting and ending blank character \n",
    "    if len(string) >= 1 and string[0] == ' ':\n",
    "        string = string[1:]\n",
    "    if len(string) >= 1 and string[-1] == ' ':\n",
    "        string = string[:-1]\n",
    "        \n",
    "    return string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9eeb34c",
   "metadata": {},
   "source": [
    "# Read Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6f49d51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import twitter-2013dev-A.txt\n",
      "Dropped 0 null rows\n",
      "\n",
      "Import twitter-2013test-A.txt\n",
      "Dropped 0 null rows\n",
      "\n",
      "Import twitter-2013train-A.txt\n",
      "Dropped 0 null rows\n",
      "\n",
      "Import twitter-2014sarcasm-A.txt\n",
      "Dropped 0 null rows\n",
      "\n",
      "Import twitter-2014test-A.txt\n",
      "Dropped 0 null rows\n",
      "\n",
      "Import twitter-2015test-A.txt\n",
      "Dropped 0 null rows\n",
      "\n",
      "Import twitter-2015train-A.txt\n",
      "Dropped 0 null rows\n",
      "\n",
      "Import twitter-2016devtest-A.txt\n",
      "Dropped 0 null rows\n",
      "\n",
      "Import twitter-2016test-A.txt\n",
      "Dropped 0 null rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "datasets = []\n",
    "\n",
    "for dataset in dataset_files:\n",
    "    print(f\"Import {dataset}\")\n",
    "    df = pd.read_csv(relative_import_path + dataset, sep=sep, header=header, names=names)\n",
    "    \n",
    "    if 'tweet' in df:\n",
    "        final_df = df[['tweet']].astype('string')\n",
    "    elif 'text' in df:\n",
    "        final_df = df[['text']]\n",
    "        final_df = final_df.rename(columns={\"text\":'tweet'})\n",
    "    \n",
    "    if 'sentiment' in df:\n",
    "        final_df = final_df.join(df['sentiment'])\n",
    "        \n",
    "    size_before = len(final_df)\n",
    "    final_df['tweet'].replace('', np.nan, inplace=True)\n",
    "    final_df['tweet'].replace(' ', np.nan, inplace=True) \n",
    "    final_df.dropna(inplace=True)\n",
    "    size_after = len(final_df)\n",
    "    \n",
    "    print(f'Dropped {size_before - size_after} null rows')\n",
    "    print()\n",
    "    \n",
    "    datasets.append(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ffdadbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Won the match #getin . Plus\\u002c tomorrow is ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Some areas of New England could see the first ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@francesco_con40 2nd worst QB. DEFINITELY Tony...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#Thailand Washington - US President Barack Oba...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Did y\\u2019all hear what Tony Romo dressed up ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1649</th>\n",
       "      <td>#WEB YouTube improves upload process with opti...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1650</th>\n",
       "      <td>Gonna change my Tumblr theme. I hope I can fin...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1651</th>\n",
       "      <td>I\\u2019m so jealous of everyone at the Justin ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1652</th>\n",
       "      <td>Jim Harbaugh\\u002c Alex Smith Drive Giants Wor...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1653</th>\n",
       "      <td>#Trending: Tim Tebow is now dating cave woman ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1654 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tweet sentiment\n",
       "0     Won the match #getin . Plus\\u002c tomorrow is ...   neutral\n",
       "1     Some areas of New England could see the first ...   neutral\n",
       "2     @francesco_con40 2nd worst QB. DEFINITELY Tony...  negative\n",
       "3     #Thailand Washington - US President Barack Oba...   neutral\n",
       "4     Did y\\u2019all hear what Tony Romo dressed up ...   neutral\n",
       "...                                                 ...       ...\n",
       "1649  #WEB YouTube improves upload process with opti...   neutral\n",
       "1650  Gonna change my Tumblr theme. I hope I can fin...  positive\n",
       "1651  I\\u2019m so jealous of everyone at the Justin ...   neutral\n",
       "1652  Jim Harbaugh\\u002c Alex Smith Drive Giants Wor...   neutral\n",
       "1653  #Trending: Tim Tebow is now dating cave woman ...   neutral\n",
       "\n",
       "[1654 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06776056",
   "metadata": {},
   "source": [
    "# Clean Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc149f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean twitter-2013dev-A.txt\n",
      "Dropped 5 duplicates.\n",
      "Dropped 0 empty strings. Final size 1649.\n",
      "\n",
      "Clean twitter-2013test-A.txt\n",
      "Dropped 11 duplicates.\n",
      "Dropped 0 empty strings. Final size 3536.\n",
      "\n",
      "Clean twitter-2013train-A.txt\n",
      "Dropped 64 duplicates.\n",
      "Dropped 0 empty strings. Final size 9620.\n",
      "\n",
      "Clean twitter-2014sarcasm-A.txt\n",
      "Dropped 0 duplicates.\n",
      "Dropped 0 empty strings. Final size 49.\n",
      "\n",
      "Clean twitter-2014test-A.txt\n",
      "Dropped 0 duplicates.\n",
      "Dropped 0 empty strings. Final size 1853.\n",
      "\n",
      "Clean twitter-2015test-A.txt\n",
      "Dropped 42 duplicates.\n",
      "Dropped 0 empty strings. Final size 2348.\n",
      "\n",
      "Clean twitter-2015train-A.txt\n",
      "Dropped 6 duplicates.\n",
      "Dropped 0 empty strings. Final size 483.\n",
      "\n",
      "Clean twitter-2016devtest-A.txt\n",
      "Dropped 0 duplicates.\n",
      "Dropped 0 empty strings. Final size 2000.\n",
      "\n",
      "Clean twitter-2016test-A.txt\n",
      "Dropped 55 duplicates.\n",
      "Dropped 1 empty strings. Final size 20576.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for (dataset, filename) in zip(datasets, dataset_files):\n",
    "    print(f\"Clean {filename}\")\n",
    "    dataset['tweet'] = dataset['tweet'].apply(cleanTweet)\n",
    "    \n",
    "    beforeSize = len(dataset)\n",
    "    dataset.drop_duplicates(inplace = True)\n",
    "    afterSize = len(dataset)\n",
    "        \n",
    "    print(f\"Dropped {beforeSize - afterSize} duplicates.\")\n",
    "    \n",
    "    beforeSize = len(dataset)\n",
    "    dataset.drop(dataset[dataset['tweet'] == ''].index, inplace=True)\n",
    "    afterSize = len(dataset)\n",
    "    \n",
    "    print(f\"Dropped {beforeSize - afterSize} empty strings. Final size {afterSize}.\")\n",
    "    \n",
    "    dataset.reset_index(inplace=True, drop=True)\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86a8d0da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"won the match . plus, tomorrow is a very busy day, with awareness day's and debates. gulp. debates...\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[0]['tweet'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ced71456",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>won the match . plus, tomorrow is a very busy ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>some areas of new england could see the first ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2nd worst qb. definitely tony romo. the man wh...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>washington - us president barack obama vowed w...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>did y'all hear what tony romo dressed up as fo...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1644</th>\n",
       "      <td>youtube improves upload process with optional ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1645</th>\n",
       "      <td>gonna change my tumblr theme. i hope i can fin...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1646</th>\n",
       "      <td>i'm so jealous of everyone at the justin biebe...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1647</th>\n",
       "      <td>jim harbaugh, alex smith drive giants world se...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1648</th>\n",
       "      <td>: tim tebow is now dating cave woman from 10,0...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1649 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tweet sentiment\n",
       "0     won the match . plus, tomorrow is a very busy ...   neutral\n",
       "1     some areas of new england could see the first ...   neutral\n",
       "2     2nd worst qb. definitely tony romo. the man wh...  negative\n",
       "3     washington - us president barack obama vowed w...   neutral\n",
       "4     did y'all hear what tony romo dressed up as fo...   neutral\n",
       "...                                                 ...       ...\n",
       "1644  youtube improves upload process with optional ...   neutral\n",
       "1645  gonna change my tumblr theme. i hope i can fin...  positive\n",
       "1646  i'm so jealous of everyone at the justin biebe...   neutral\n",
       "1647  jim harbaugh, alex smith drive giants world se...   neutral\n",
       "1648  : tim tebow is now dating cave woman from 10,0...   neutral\n",
       "\n",
       "[1649 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d979d42d",
   "metadata": {},
   "source": [
    "# Export cleaned datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e715fb8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Export twitter-2013dev-A\n",
      "Export twitter-2013test-A\n",
      "Export twitter-2013train-A\n",
      "Export twitter-2014sarcasm-A\n",
      "Export twitter-2014test-A\n",
      "Export twitter-2015test-A\n",
      "Export twitter-2015train-A\n",
      "Export twitter-2016devtest-A\n",
      "Export twitter-2016test-A\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(relative_export_path):\n",
    "    os.mkdir(relative_export_path)\n",
    "\n",
    "for (dataset, filename) in zip(datasets, dataset_files):\n",
    "    filename, ext = os.path.splitext(filename)\n",
    "    print(f\"Export {filename}\")\n",
    "    dataset.to_csv(relative_export_path + filename + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa407e7",
   "metadata": {},
   "source": [
    "# Export final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b2af2737",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.concat(datasets)\n",
    "dataset.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "24fd3b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv(relative_export_path + 'data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "783a69a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Dataset Size: 42114\n"
     ]
    }
   ],
   "source": [
    "print(f'Final Dataset Size: {len(dataset)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
